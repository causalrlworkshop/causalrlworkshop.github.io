---
layout: default
---

<div class="row">
<p>
Deep Learning has enabled significant improvements in areas as diverse as computer vision, text understanding and reinforcement learning. However, a major challenge that still stands is the ability to generalize outside of the i.i.d setting, when we care about generalization or fast adaptation to distributions that are different from the main training distribution. It has been argued that this requires not only learning the statistical correlations within data, but the causal model underlying the data.

Causal models exploit the conditional distribution of the target variables given the corresponding direct causal predictors and must remain identical under interventions on variables other than the target variable. This invariance idea is closely linked to causality and has been discussed, for example, under the term ‘modularity’ (Pearl, 2009; Schölkopf et al., 2012). Hence, causal knowledge supports decision making in two ways: by allowing us to predict the consequences of different actions under the given circumstances and by helping to make diagnoses that suggest which interventions will be effective.  If the data was really generated from the composition of independent causal mechanisms (Peters et al., 2017), then there exists a good factorization of knowledge that mimics that structure. If in addition, at each time step, agents in the real world tend to only be able to change one or very few high-level variables (or the associated mechanisms producing them), then assumption of small change (in the right representation) should be generally valid. Hence we should be able to obtain fast transfer, by recovering a good approximation of the true causal decomposition into independent mechanisms (to the extent that the observations and interventions can reveal those mechanisms).

</p>
<p>
The goal of this workshop is to investigate how much progress is possible by framing the learning problem beyond learning correlations, that is, by uncovering and leveraging causal relations.
</p>

<p>
Key questions to be addressed and discussed include:
</p>

<ul>
<li> What is the role of an underlying causal model in decision making? </li>
<li> What is the difference between a prediction that is made with a causal model and that with a non‐causal model? </li>
<li> The way current RL agents explore environments appears less intelligent than the way that human learners explore. One reason for this disparity may be that humans, when faced with a novel environment, do not merely observe, they also interact with the world and effect the world with actions. Maintaining a causal model of the world allows the learner to maintain plausible hypotheses and design experiments to test these hypotheses. </li>
<li> Maintaining a distributional belief about the agent's model of the world as a tool for exploration (minimize entropy, maximize knowledge acquisition). </li>
<li> The importance of causality to advantageous decision-making could also be potentially problematic as research into causal explanations has shown that people often have only rough, skeletal knowledge about causal mechanisms. Therefore people’s causal knowledge only allows for very rough and sometimes incorrect predictions of consequences. Given that our causal knowledge is incomplete or sometimes wrong, it might be harmful to try to base decisions on causal considerations. </li>
</ul>
</div>

<div id="sponsors" class="row">
<h2>Sponsors</h2>
<div class="break"></div>
<div>
<p>
  <a href="http://deepmind.com"><img src="images/deepmind.png" height="80px"/></a>
</p>
</div>
</div>

<div id="organizers" class="row">
<h2>Organizers</h2>
<div class="break"></div>
<ul>
  <li><b><a href="https://scholar.google.ca/citations?user=dxwPYhQAAAAJ&hl=en">Rosemary Nan Ke</a></b> (Mila, University of Montreal)</li>
  <li><b><a href="https://scholar.google.com/citations?user=krrh6OUAAAAJ&hl=en&oi=ao">Anirudh Goyal</a></b> (Mila, University of Montreal)</li>
  <li><b><a href="http://www.janexwang.com/">Jane Wang</a></b> (Deepmind)</li>
  <li><b><a href="http://www.is.mpg.de/~sbauer"> Stefan Bauer</a></b> (Max Planck Institute for Intelligent Systems)</li>
  <li><b><a href="https://csilviavr.github.io/">Silvia Chiappa</a></b> (Deepmind)</li>
  <li><b><a href="https://jovana-mitrovic.github.io/">Jovana Mitrovic</a></b> (Deepmind)</li>
  <li><b><a href="http://thphn.com/">Theophane Weber</a></b> (Deepmind)</li>
  <li><b><a href="https://danilorezende.com/">Danilo Rezende</a></b> (Deepmind)</li>
</ul>
</div>


<div id="references" class="row">
<h2>References</h2>
<ul>
  <li> Anderson, J. R. (1975). Computer simulation of a language acquisition system: A first report. In R. Solso (Ed.). Information processing and cognition. Hillsdale, N.J.: Lawrence Erlbaum.</li>
</ul>
</div>
